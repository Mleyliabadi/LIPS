{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e14d4a",
   "metadata": {},
   "source": [
    "# Inference time measurement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8290d66",
   "metadata": {},
   "source": [
    "To be able to run this experimentation, [Grid2op](https://github.com/rte-france/Grid2Op) (1.7.1) and [LightSim2Grid](https://github.com/BDonnot/lightsim2grid) (0.7.0) are required. See the corresponding links for more information concerning their installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef28d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "from lips.utils import get_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbf3d0",
   "metadata": {},
   "source": [
    "# TOC\n",
    "- [Device Selection](#device)\n",
    "- [Environment: `l2rpn_case14_sandbox`](#env_case14)\n",
    "    - [Benchmark Selection](#benchmark_select)\n",
    "      - [Benchmark1](#benchmark1)\n",
    "      - [Benchmark2](#benchmark2)\n",
    "- [Environment: `l2rpn_neurips_2020_track1_small`](#env_nips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2388b",
   "metadata": {},
   "source": [
    "## Select a device on which the model should be evaluated <a id=\"device\"></a>\n",
    "On the basis of GPU or CPU device, the results may be vary significantly. You can choose one of the following block in each kernel to using whether GPU or CPU device. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048aa18",
   "metadata": {},
   "source": [
    "### Using A GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4a3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device = \"GPU\"\n",
    "gpus = tf.config.experimental.list_physical_devices(device)\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[3], device)\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc1ebd",
   "metadata": {},
   "source": [
    "### Using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b92ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = \"CPU\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825dce6f",
   "metadata": {},
   "source": [
    "### Show the list of used devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9e1ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f9584",
   "metadata": {},
   "source": [
    "# Environment : \"l2rpn_case14_sandbox\" <a id=\"env_case14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2f6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent # it is supposed that the notebook had run from getting_started folder\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_case14_sandbox\"\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_case14_sandbox.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "TRAINED_MODEL_PATH = LIPS_PATH / \"trained_models\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7f735",
   "metadata": {},
   "source": [
    "## Select a benchmark <a id=\"benchmark_select\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9c95b",
   "metadata": {},
   "source": [
    "### Benchmark1 <a id=\"benchmark1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306de8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc26518",
   "metadata": {},
   "source": [
    "### Physics solver time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1a797",
   "metadata": {},
   "source": [
    "Physics solver takes 0.02 miliseconds to solve a powerflow. However the physics solver time for the benchmark1 is computed as follows:\n",
    "$$\\underbrace{3}_\\textrm{# situations} \\times \\underbrace{6}_\\textrm{# topologies} \\times \\frac{\\textrm{security analysis time}}{20}$$, where $20$ is number of the lines in this benchmark. In our case the *security analysis* takes 0.02 ms to be solved. So the solver time is $3 \\times 6 \\times 0.02 = 0.36 ms$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c320af69",
   "metadata": {},
   "source": [
    "### Select a model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6521df",
   "metadata": {},
   "source": [
    "#### Fully connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b9de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9101cf",
   "metadata": {},
   "source": [
    "##### Load it from a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f00bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 20:13:02.772778: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark1)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af0b87",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca401271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the inference time\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(10):\n",
    "    tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0c327",
   "metadata": {},
   "source": [
    "The inference time should be reported per powerflow. So it should be devided by $10000$ which represents the size of the data in test data dataset. For the sake of comparison which physics solver, we would report it in miliseconds. So, it should be multiplied by $1000$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a711e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 0.018338852387387305\n",
      "Inference time from Machine Learning category and using GPU: 0.0044172982173040515\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd00c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.02155673010274768\n",
      "Inference time from Machine Learning category and using CPU: 0.004848378957249224\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c65bd",
   "metadata": {},
   "source": [
    "##### Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3afc45ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and GPU is: 19.63\n",
      "Speed up factor from ML point of view using FullyConnected model and GPU is: 81.50\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (0.36 / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (0.36 / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e5820fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 16.70\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 74.25\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (0.36 / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (0.36 / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605439df",
   "metadata": {},
   "source": [
    "#### LeapNet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6745e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import LeapNet\n",
    "from lips.dataset.scaler import PowerGridScaler\n",
    "\n",
    "leap_net = LeapNet(name=\"tf_leapnet\",\n",
    "                   bench_config_path=BENCH_CONFIG_PATH,\n",
    "                   bench_config_name=\"Benchmark1\",\n",
    "                   sim_config_path=SIM_CONFIG_PATH / \"tf_leapnet.ini\",\n",
    "                   sim_config_name=\"DEFAULT\",\n",
    "                   scaler=PowerGridScaler,\n",
    "                   log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c3c10",
   "metadata": {},
   "source": [
    "Load the model for the convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742e2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark1)\n",
    "leap_net.restore(path=LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac11c5",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the inference time\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(10):\n",
    "    leapnet_metrics = benchmark1.evaluate_simulator(augmented_simulator=leap_net,\n",
    "                                                    eval_batch_size=128,\n",
    "                                                    dataset=\"all\",\n",
    "                                                    shuffle=False,\n",
    "                                                    save_path=None,\n",
    "                                                    save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(leapnet_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(leapnet_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70ca7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 0.14272481479216367\n",
      "Inference time from Machine Learning category and using GPU: 0.10670942533994095\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de80ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.1397597827226855\n",
      "Inference time from Machine Learning category and using CPU: 0.11120240544900296\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b67ad",
   "metadata": {},
   "source": [
    "##### Computing the speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e42da053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using LeapNet model and GPU is: 2.52\n",
      "Speed up factor from ML point of view using LeapNet model and GPU is: 3.37\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using LeapNet model and {} is: {:.2f}\".format(device, (0.36 / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using LeapNet model and {} is: {:.2f}\".format(device, (0.36 / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cedb5282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using LeapNet model and CPU is: 2.58\n",
      "Speed up factor from ML point of view using LeapNet model and CPU is: 3.24\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using LeapNet model and {} is: {:.2f}\".format(device, (0.36 / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using LeapNet model and {} is: {:.2f}\".format(device, (0.36 / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f91db",
   "metadata": {},
   "source": [
    "## Benchmark2 <a id=\"benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51dc359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811aa785",
   "metadata": {},
   "source": [
    "### Physics solver time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7c59f",
   "metadata": {},
   "source": [
    "Apart of first benchmark (security analysis) where the inverse of `Y_bus` matrix could be computed once and the observatiosn could be generated in parallel, the other two benchmarks require to compute this matrix inversion for each flow computation. Hence, to be able to compute the physics solver time, we can use the following times:\n",
    "\n",
    "$$ \\textrm{_timer_preproc} + \\textrm{_timer_solver} + \\textrm{_timer_postproc}$$\n",
    "\n",
    "The details explanations for each of these steps are provided [here](https://docs.google.com/document/d/1MWj1NUj4hbPuMMzu0ty9Md_qk9mnLz88chEOi3TwJJU/edit#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ea030",
   "metadata": {},
   "source": [
    "In the next cell we compute the flow over 1000 observations, and finally we report the time required for one powerflow to be comptued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "time_physics_solver = list()\n",
    "for i in range(10):\n",
    "    benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(10000),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "                 benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "                 benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b89ee817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics solver computation time for benchmark 2 and one power flow is: 0.04083034829236567 s\n"
     ]
    }
   ],
   "source": [
    "physics_solver_time = np.mean(time_physics_solver)\n",
    "print(\"Physics solver computation time for benchmark 2 and one power flow is: {} s\".format(physics_solver_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2c3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = 0.04083034829236567"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748565d9",
   "metadata": {},
   "source": [
    "### Select a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13f13e",
   "metadata": {},
   "source": [
    "#### Fully Connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853c3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6dbdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 11:51:24.243887: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-07 11:51:24.690001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46720 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:c3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark2)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b747a6",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the inference time\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(10):\n",
    "    tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e5f096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.21410137366037815\n",
      "Inference time from Machine Learning category and using CPU: 0.05234153128694743\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "411a8876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 0.017661474130582066\n",
      "Inference time from Machine Learning category and using GPU: 0.004774301669094712\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87067bcb",
   "metadata": {},
   "source": [
    "##### Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d4c50419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 0.19\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 0.78\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a104af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and GPU is: 2.31\n",
      "Speed up factor from ML point of view using FullyConnected model and GPU is: 8.55\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72b94b",
   "metadata": {},
   "source": [
    "#### LeapNet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc15e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import LeapNet\n",
    "from lips.dataset.scaler import PowerGridScaler\n",
    "\n",
    "leap_net = LeapNet(name=\"tf_leapnet\",\n",
    "                   bench_config_path=BENCH_CONFIG_PATH,\n",
    "                   bench_config_name=\"Benchmark1\",\n",
    "                   sim_config_path=SIM_CONFIG_PATH / \"tf_leapnet.ini\",\n",
    "                   sim_config_name=\"DEFAULT\",\n",
    "                   scaler=PowerGridScaler,\n",
    "                   log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038910f",
   "metadata": {},
   "source": [
    "Load the model for the convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fdd17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark2)\n",
    "leap_net.restore(path=LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3617c2c",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19158910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the inference time\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(10):\n",
    "    leapnet_metrics = benchmark2.evaluate_simulator(augmented_simulator=leap_net,\n",
    "                                                    eval_batch_size=128,\n",
    "                                                    dataset=\"all\",\n",
    "                                                    shuffle=False,\n",
    "                                                    save_path=None,\n",
    "                                                    save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(leapnet_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(leapnet_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "128f49dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.22096358130220323\n",
      "Inference time from Machine Learning category and using CPU: 0.05369499467778951\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02bbc3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 0.1634221963491291\n",
      "Inference time from Machine Learning category and using GPU: 0.1115585584449582\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e9141",
   "metadata": {},
   "source": [
    "##### Computing speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6bb576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using LeapNet model and CPU is: 0.18\n",
      "Speed up factor from ML point of view using LeapNet model and CPU is: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using LeapNet model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using LeapNet model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30bb84cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using LeapNet model and GPU is: 0.25\n",
      "Speed up factor from ML point of view using LeapNet model and GPU is: 0.37\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using LeapNet model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using LeapNet model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acec3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5b0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ce8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed2f1c4c",
   "metadata": {},
   "source": [
    "# Environment : \"l2rpn_neurips_2020_track1_small\" <a id=\"env_nips\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21978c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent # it is supposed that the notebook had run from getting_started folder\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_neurips_2020_track1_small\"\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_neurips_2020_track1_small.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "TRAINED_MODEL_PATH = LIPS_PATH / \"trained_models\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e8031d",
   "metadata": {},
   "source": [
    "## Benchmark2 <a id=\"benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0160efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b599f87a",
   "metadata": {},
   "source": [
    "### Physics solver time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62fb2cc",
   "metadata": {},
   "source": [
    "Apart of first benchmark (security analysis) where the inverse of `Y_bus` matrix could be computed once and the observatiosn could be generated in parallel, the other two benchmarks require to compute this matrix inversion for each flow computation. Hence, to be able to compute the physics solver time, we can use the following times:\n",
    "\n",
    "$$ \\textrm{_timer_preproc} + \\textrm{_timer_solver} + \\textrm{_timer_postproc}$$\n",
    "\n",
    "The details explanations for each of these steps are provided [here](https://docs.google.com/document/d/1MWj1NUj4hbPuMMzu0ty9Md_qk9mnLz88chEOi3TwJJU/edit#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c51b6",
   "metadata": {},
   "source": [
    "In the next cell we compute the flow over 1000 observations, and finally we report the time required for one powerflow to be comptued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "time_physics_solver = list()\n",
    "for i in range(10):\n",
    "    benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(10000),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "                 benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "                 benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c680f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics solver computation time for benchmark 2 and one power flow is: 0.05780877992510795 s\n"
     ]
    }
   ],
   "source": [
    "physics_solver_time = np.mean(time_physics_solver)\n",
    "print(\"Physics solver computation time for benchmark 2 and one power flow is: {} s\".format(physics_solver_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fac06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = 0.05780877992510795"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50034ba3",
   "metadata": {},
   "source": [
    "### Select a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c560e2",
   "metadata": {},
   "source": [
    "#### Fully Connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa05df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2abaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 12:54:23.513096: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-07 12:54:23.968420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 516 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:c3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "LOAD_PATH = get_path(TRAINED_MODEL_PATH, benchmark2)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0534371",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567426fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the inference time\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(10):\n",
    "    tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a777629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.21410137366037815\n",
      "Inference time from Machine Learning category and using CPU: 0.05234153128694743\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f36f2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 0.20453928930219262\n",
      "Inference time from Machine Learning category and using GPU: 0.0727451688842848\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651da0d7",
   "metadata": {},
   "source": [
    "##### Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cff13932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 0.19\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 0.78\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55572a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and GPU is: 0.28\n",
      "Speed up factor from ML point of view using FullyConnected model and GPU is: 0.79\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12eab99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82742f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd6410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bdd79c9",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27bb4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "from lightsim2grid import LightSimBackend\n",
    "env = grid2op.make(\"l2rpn_case14_sandbox\", backend=LightSimBackend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c84def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Agent import DoNothingAgent, RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12454e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DoNothingAgent(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f263ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "374a3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = env.reward_range[0]\n",
    "done = False\n",
    "action = agent.act(obs, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4298ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time :  6.270804442465305e-05\n",
      "solver time :  8.620298467576504e-05\n",
      "postprocess time :  0.00012840190902352333\n"
     ]
    }
   ],
   "source": [
    "print(\"preprocess time : \", env.backend._timer_preproc)\n",
    "print(\"solver time : \", env.backend._timer_solver)\n",
    "print(\"postprocess time : \", env.backend._timer_postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d3707a",
   "metadata": {},
   "outputs": [
    {
     "ename": "Grid2OpException",
     "evalue": "Grid2OpException \"Impossible to make a step with a non initialized backend. Have you called \"env.reset()\" after the last game over ?\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGrid2OpException\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m done:\n\u001b[0;32m----> 3\u001b[0m     obs, reward, info, done \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lips/lib/python3.8/site-packages/grid2op/Environment/BaseEnv.py:2775\u001b[0m, in \u001b[0;36mBaseEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   2772\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EnvError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis environment is closed. You cannot use it anymore.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_init:\n\u001b[0;32m-> 2775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Grid2OpException(\n\u001b[1;32m   2776\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImpossible to make a step with a non initialized backend. Have you called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2777\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m after the last game over ?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2778\u001b[0m     )\n\u001b[1;32m   2779\u001b[0m \u001b[38;5;66;03m# I did something after calling \"env.seed()\" which is\u001b[39;00m\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;66;03m# somehow \"env.step()\" or \"env.reset()\"\u001b[39;00m\n\u001b[1;32m   2781\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_just_been_seeded \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;01mFalse\u001b[39;00m  \n",
      "\u001b[0;31mGrid2OpException\u001b[0m: Grid2OpException \"Impossible to make a step with a non initialized backend. Have you called \"env.reset()\" after the last game over ?\""
     ]
    }
   ],
   "source": [
    "done=True\n",
    "while done:\n",
    "    obs, reward, info, done = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e4123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "329d32c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time :  0.016066802898421884\n",
      "solver time :  0.0222038880456239\n",
      "postprocess time :  0.079864083789289\n"
     ]
    }
   ],
   "source": [
    "print(\"preprocess time : \", env.backend._timer_preproc)\n",
    "print(\"solver time : \", env.backend._timer_solver)\n",
    "print(\"postprocess time : \", env.backend._timer_postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4167308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time :  0.00024596485309302807\n",
      "solver time :  0.0002572669181972742\n",
      "postprocess time :  0.0014893850311636925\n"
     ]
    }
   ],
   "source": [
    "print(\"preprocess time : \", env.backend._timer_preproc)\n",
    "print(\"solver time : \", env.backend._timer_solver)\n",
    "print(\"postprocess time : \", env.backend._timer_postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bdd6d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time :  0.00032253097742795944\n",
      "solver time :  0.0003424778115004301\n",
      "postprocess time :  0.002225663047283888\n"
     ]
    }
   ],
   "source": [
    "print(\"preprocess time : \", env.backend._timer_preproc)\n",
    "print(\"solver time : \", env.backend._timer_solver)\n",
    "print(\"postprocess time : \", env.backend._timer_postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0455a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22ded633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:02<00:00, 160.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n"
     ]
    }
   ],
   "source": [
    "benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                        nb_sample_val=int(1),\n",
    "                        nb_sample_test=int(10000),\n",
    "                        nb_sample_test_ood_topo=int(1),\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9bfbd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time :  0.007299850229173899\n",
      "solver time :  0.012052051490172744\n",
      "postprocess time :  0.021055438788607717\n"
     ]
    }
   ],
   "source": [
    "simulator = benchmark2_tmp.test_simulator._simulator\n",
    "print(\"preprocess time : \", simulator.backend._timer_preproc)\n",
    "print(\"solver time : \", simulator.backend._timer_solver)\n",
    "print(\"postprocess time : \", simulator.backend._timer_postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8246a62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndRed time:  2.020367025397718\n",
      "ML time:  8.081468101590872\n"
     ]
    }
   ],
   "source": [
    "solver_time = (simulator.backend._timer_preproc + simulator.backend._timer_solver + simulator.backend._timer_postproc)\n",
    "print(\"IndRed time: \", solver_time / 2e-2)\n",
    "print(\"ML time: \", solver_time / 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66abc801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006371969357132912"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ee50aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time :  0.00016485294327139854\n",
      "solver time :  0.00018332712352275848\n",
      "postprocess time :  0.000358447665348649\n"
     ]
    }
   ],
   "source": [
    "simulator = benchmark2_tmp.training_simulator._simulator\n",
    "print(\"preprocess time : \", simulator.backend._timer_preproc)\n",
    "print(\"solver time : \", simulator.backend._timer_solver)\n",
    "print(\"postprocess time : \", simulator.backend._timer_postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9baee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time :  0.00012895278632640839\n",
      "solver time :  0.000169272068887949\n",
      "postprocess time :  0.0003389720804989338\n"
     ]
    }
   ],
   "source": [
    "simulator = benchmark2_tmp.val_simulator._simulator\n",
    "print(\"preprocess time : \", simulator.backend._timer_preproc)\n",
    "print(\"solver time : \", simulator.backend._timer_solver)\n",
    "print(\"postprocess time : \", simulator.backend._timer_postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ea5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lips",
   "language": "python",
   "name": "lips"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
