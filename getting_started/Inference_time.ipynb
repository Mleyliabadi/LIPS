{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69bd90c",
   "metadata": {},
   "source": [
    "# Inference time measurement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f253a0",
   "metadata": {},
   "source": [
    "To be able to run this experimentation, [Grid2op](https://github.com/rte-france/Grid2Op) (1.7.1) and [LightSim2Grid](https://github.com/BDonnot/lightsim2grid) (0.7.0) are required. See the corresponding links for more information concerning their installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29ea519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "from lips.utils import get_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926afae9",
   "metadata": {},
   "source": [
    "# TOC\n",
    "- [Device Selection](#device)\n",
    "- [Environment: `l2rpn_case14_sandbox`](#env_case14)\n",
    "    - [Benchmark1](#benchmark1)\n",
    "        - [Physics solver time](#14_solver_bench1)\n",
    "    - [Benchmark2](#benchmark2)\n",
    "        - [Physics solver time](#14_solver_bench2)\n",
    "- [Environment: `l2rpn_neurips_2020_track1_small`](#env_nips)\n",
    "    - [Benchmark1](#nips_benchmark1)\n",
    "        - [Physics solver time](#nips_solver_bench1)\n",
    "    - [Benchmark2](#nips_benchmark2)\n",
    "        - [Physics solver time](#nips_solver_bench2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd639c0",
   "metadata": {},
   "source": [
    "## Select a device on which the model should be evaluated <a id=\"device\"></a>\n",
    "On the basis of GPU or CPU device, the results may be vary significantly. You can choose one of the following block in each kernel to using whether GPU or CPU device. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890432fc",
   "metadata": {},
   "source": [
    "### Using A GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1812cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device = \"GPU\"\n",
    "gpus = tf.config.experimental.list_physical_devices(device)\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], device)\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d73cc",
   "metadata": {},
   "source": [
    "### Using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383c8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = \"CPU\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd41961",
   "metadata": {},
   "source": [
    "### Show the list of used devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd048bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 12:15:03.211276: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-09 12:15:03.211307: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: rte-01\n",
      "2022-06-09 12:15:03.211312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: rte-01\n",
      "2022-06-09 12:15:03.211410: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.43.4\n",
      "2022-06-09 12:15:03.211427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.43.4\n",
      "2022-06-09 12:15:03.211431: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.43.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78175a81",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\">Environment : \"l2rpn_case14_sandbox\"</h1> <a id=\"env_case14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "af7486a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent # it is supposed that the notebook had run from getting_started folder\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_case14_sandbox\"\n",
    "#BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_case14_sandbox.ini\"\n",
    "# DO NOT CONSIDER THE TAU VECTOR\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_case14_sandbox_time.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "TRAINED_MODEL_PATH = LIPS_PATH / \"trained_models\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7a0b8",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Benchmark1 </h2> <a id=\"benchmark1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "1411fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4385b938",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"14_solver_bench1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0abc3e",
   "metadata": {},
   "source": [
    "Physics solver takes 0.02 miliseconds to solve a powerflow. However the physics solver time for the benchmark1 is computed as follows:\n",
    "$$\\underbrace{\\#Samples}_\\textrm{# situations} \\times \\underbrace{(3! + 1)}_\\textrm{# topologies} \\times \\frac{\\textrm{security analysis time}}{20}$$, where $20$ is number of the lines in this benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac51dc0",
   "metadata": {},
   "source": [
    "#### This step is added to consider preprocessing for solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 3\n",
    "data_size = 1000\n",
    "\n",
    "time_physics_solver = list()\n",
    "time_preproc = list()\n",
    "for i in range(NB_RUN):\n",
    "    benchmark1_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "    \n",
    "    benchmark1_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(data_size),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    simulator = benchmark1_tmp.test_simulator\n",
    "    total_time = simulator._timer_preproc + simulator._timer_solver + simulator._timer_postproc\n",
    "    time_preproc.append(simulator._timer_preproc)\n",
    "    #total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "dc90d8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing time required for generating 1000000 samples: 36.64s\n"
     ]
    }
   ],
   "source": [
    "nb_samples = int(1e6)\n",
    "time_preprocess = (np.mean(time_preproc) / 1000) * 1e6\n",
    "print(f\"preprocessing time required for generating {nb_samples} samples: {time_preprocess:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b06ef",
   "metadata": {},
   "source": [
    "#### Security Analysis\n",
    "Do the Security Analysis. Source : https://github.com/BDonnot/lightsim2grid/blob/master/examples/security_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c70e55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For environment: l2rpn_case14_sandbox (19 n-1 simulated)\n",
      "Total time spent in \"computer\" to solve everything: 0.4ms (52512 pf / s), 0.02 ms / pf)\n",
      "\t - time to compute the coefficients to simulate line disconnection: 0.02ms\n",
      "\t - time to pre process Ybus: 0.02ms\n",
      "\t - time to perform powerflows: 0.31ms (61632 pf / s, 0.02 ms / pf)\n",
      "In addition, it took 0.01 ms to retrieve the current from the complex voltages (in total 50623.7 pf /s, 0.02 ms / pf)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import grid2op\n",
    "from grid2op.Parameters import Parameters\n",
    "from lightsim2grid import LightSimBackend, SecurityAnalysis\n",
    "\n",
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "\n",
    "test = False\n",
    "# Create the grid2op environment\n",
    "param = Parameters()\n",
    "param.NO_OVERFLOW_DISCONNECTION = True\n",
    "env = grid2op.make(env_name,\n",
    "                   backend=LightSimBackend(),\n",
    "                   # ignore the protection, that are NOT simulated\n",
    "                   # by the TimeSerie module !\n",
    "                   param=param,\n",
    "                   test=test)\n",
    "\n",
    "# Run the environment on a scenario using the TimeSerie module\n",
    "NB_RUN = 10\n",
    "total_times = list()\n",
    "s1 = list()\n",
    "s2 = list()\n",
    "s3 = list()\n",
    "for i in range(NB_RUN):\n",
    "    env.fast_forward_chronics(2*24*(60/5))\n",
    "    beg_ = time.perf_counter()\n",
    "    security_analysis = SecurityAnalysis(env)\n",
    "    s1.append(time.perf_counter() - beg_)\n",
    "    beg_ = time.perf_counter()\n",
    "    security_analysis.add_all_n1_contingencies()\n",
    "    s2.append(time.perf_counter() - beg_)\n",
    "    beg_ = time.perf_counter()\n",
    "    p_or, a_or, voltages = security_analysis.get_flows()\n",
    "    s3.append(time.perf_counter() - beg_)\n",
    "    total_times.append(security_analysis.computer.total_time())\n",
    "    \n",
    "# the 3 lines above are the only lines you need to do to perform a security analysis !\n",
    "\n",
    "computer = security_analysis.computer\n",
    "print(f\"For environment: {env_name} ({computer.nb_solved()} n-1 simulated)\")\n",
    "print(f\"Total time spent in \\\"computer\\\" to solve everything: {1e3*computer.total_time():.1f}ms \"\n",
    "      f\"({computer.nb_solved() / computer.total_time():.0f} pf / s), \"\n",
    "      f\"{1000.*computer.total_time() / computer.nb_solved():.2f} ms / pf)\")\n",
    "print(f\"\\t - time to compute the coefficients to simulate line disconnection: {1e3*computer.preprocessing_time():.2f}ms\")\n",
    "print(f\"\\t - time to pre process Ybus: {1e3*computer.modif_Ybus_time():.2f}ms\")\n",
    "print(f\"\\t - time to perform powerflows: {1e3*computer.solver_time():.2f}ms \"\n",
    "      f\"({computer.nb_solved() / computer.solver_time():.0f} pf / s, \"\n",
    "      f\"{1000.*computer.solver_time() / computer.nb_solved():.2f} ms / pf)\")\n",
    "print(f\"In addition, it took {1e3*computer.amps_computation_time():.2f} ms to retrieve the current \"\n",
    "      f\"from the complex voltages (in total \"\n",
    "      f\"{computer.nb_solved() / ( computer.total_time() + computer.amps_computation_time()):.1f} \"\n",
    "      \"pf /s, \"\n",
    "      f\"{1000.*( computer.total_time() + computer.amps_computation_time()) / computer.nb_solved():.2f} ms / pf)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "840af82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.63 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "nb_samples = int(1e6)\n",
    "# Add the preprocessing time\n",
    "# physics_solver_time = ((1e3*np.mean(total_times) / computer.nb_solved()) * nb_samples)/1e3 + time_preprocess\n",
    "# Do not consider this preprocessing time\n",
    "physics_solver_time = ((1e3*np.mean(total_times) / computer.nb_solved()) * nb_samples)/1e3\n",
    "print(f\"{physics_solver_time:.2f} s for {nb_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed42c7",
   "metadata": {},
   "source": [
    "Security analysis init take more time than two other steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5fcca039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01222042003646493"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1925e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.752887714654207e-05"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8640c0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00043623053934425113"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1c1df",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> Fully connected model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c8796421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"CONFIG2\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cdb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_fc.train(train_dataset=benchmark1.train_dataset,\n",
    "            val_dataset=benchmark1.val_dataset,\n",
    "            epochs=2\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d03c47",
   "metadata": {},
   "source": [
    "##### Augment the datasize to represent the realistic power network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "bf2e11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(benchmark, size=1e6):\n",
    "    data_size = benchmark._test_dataset.size\n",
    "    if size < data_size:\n",
    "        raise ValueError(\"You cannot reduce the data size using this function\")\n",
    "    factor = int(size / data_size)\n",
    "    \n",
    "    for nm_, arr_ in benchmark._test_dataset.data.items():\n",
    "        if nm_ == \"line_status\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=int)\n",
    "        elif nm_ == \"topo_vect\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=bool)\n",
    "        else:\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=np.float32)\n",
    "        \n",
    "    benchmark._test_dataset.size = int(size)\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "360ba525",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = augment_data(benchmark1, size=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "d9200f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark1._test_dataset.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538a212",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c657bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 5\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=nb_samples,\n",
    "                                                  dataset=\"test\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e66dc",
   "metadata": {},
   "source": [
    "The inference time should be reported per powerflow. So it should be devided by $10000$ which represents the size of the data in test data dataset. For the sake of comparison which physics solver, we would report it in miliseconds. So, it should be multiplied by $1000$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb693493",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "10f595c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.0008 ms/pf\n",
      "Inference time from Machine Learning category and using CPU: 0.0008 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "66147165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.83 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using CPU: 0.76 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da21474",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "42659a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 67.26\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 73.20\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8b2c2",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> LeapNet model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "35041d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import LeapNet\n",
    "from lips.dataset.scaler import PowerGridScaler\n",
    "\n",
    "leap_net = LeapNet(name=\"tf_leapnet\",\n",
    "                   bench_config_path=BENCH_CONFIG_PATH,\n",
    "                   bench_config_name=\"Benchmark1\",\n",
    "                   sim_config_path=SIM_CONFIG_PATH / \"tf_leapnet.ini\",\n",
    "                   sim_config_name=\"DEFAULT\",\n",
    "                   scaler=PowerGridScaler,\n",
    "                   topo_vect_to_tau=\"given_list\",\n",
    "                   kwargs_tau=[(4, (2, 1, 2, 1, 2)), (1, (1, 2, 1, 2, 2, 2)), (5, (1, 1, 2, 2, 1, 2, 2))],\n",
    "                   log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51432384",
   "metadata": {},
   "outputs": [],
   "source": [
    "leap_net.train(train_dataset=benchmark1.train_dataset,\n",
    "               val_dataset=benchmark1.val_dataset,\n",
    "               epochs=2\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab3779",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 5\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    leapnet_metrics = benchmark1.evaluate_simulator(augmented_simulator=leap_net,\n",
    "                                                    eval_batch_size=nb_samples,\n",
    "                                                    dataset=\"test\",\n",
    "                                                    shuffle=False,\n",
    "                                                    save_path=None,\n",
    "                                                    save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(leapnet_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(leapnet_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0581b08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'ML': {'MSE_avg': {'a_or': 3804.31103515625,\n",
       "    'a_ex': 5778.8916015625},\n",
       "   'MAE_avg': {'a_or': 31.03605079650879, 'a_ex': 40.569061279296875},\n",
       "   'TIME_INF': 10.329449051991105},\n",
       "  'Physics': {},\n",
       "  'IndRed': {'TIME_INF': 9.30644133198075}}}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leapnet_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2beef5",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "265c96d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.98 ms/pf\n",
      "Inference time from Machine Learning category and using CPU: 1.00 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "03947d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 9.76 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using CPU: 10.04 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1429c5",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "3ce7602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 5.70\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 5.54\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2d803",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Benchmark2</h2> <a id=\"benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "29ea1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb726bd4",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"14_solver_bench2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b8af8",
   "metadata": {},
   "source": [
    "Apart of first benchmark (security analysis) where the inverse of `Y_bus` matrix could be computed once and the observatiosn could be generated in parallel, the other two benchmarks require to compute this matrix inversion for each flow computation. Hence, to be able to compute the physics solver time, we can use the following times:\n",
    "\n",
    "$$ \\textrm{_timer_preproc} + \\textrm{_timer_solver} + \\textrm{_timer_postproc}$$\n",
    "\n",
    "The details explanations for each of these steps are provided [here](https://docs.google.com/document/d/1MWj1NUj4hbPuMMzu0ty9Md_qk9mnLz88chEOi3TwJJU/edit#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13995216",
   "metadata": {},
   "source": [
    "In the next cell we compute the flow over 1000 observations, and finally we report the time required for one powerflow to be comptued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 3\n",
    "data_size = 1000\n",
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "time_physics_solver = list()\n",
    "dc_time = list()\n",
    "for i in range(NB_RUN):\n",
    "    benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(data_size),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    simulator = benchmark2_tmp.test_simulator\n",
    "    total_time = simulator._timer_preproc + simulator._timer_solver + simulator._timer_postproc\n",
    "    dc_time.append(simulator._timer_preproc)\n",
    "    #total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "caa35d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics solver computation time for benchmark 2 over 3 runs is: 55.627445337695505s for 1000 samples\n",
      "Physics solver computation time for benchmark 2 over 3 runs and for one powerflow is: 55.627445337695505 ms/pf\n"
     ]
    }
   ],
   "source": [
    "physics_solver_time_env1_bench2 = np.mean(time_physics_solver)\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs is: {}s for {} samples\".format(NB_RUN, physics_solver_time, data_size))\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs and for one powerflow is: {} ms/pf\".format(NB_RUN, (physics_solver_time/data_size)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ccf6b661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.10 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "nb_samples = int(1e6)\n",
    "physics_solver_time = (physics_solver_time_env1_bench2/1000)*nb_samples\n",
    "print(f\"{physics_solver_time:.2f} s for {nb_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b2a381",
   "metadata": {},
   "source": [
    "#### DC solver time corresponds to preprocessing where the solver is initialized using DC approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "4bbcf931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.12637775950134\n"
     ]
    }
   ],
   "source": [
    "DC_solver_time = (np.mean(dc_time)/1000)*nb_samples\n",
    "print(DC_solver_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29716e13",
   "metadata": {},
   "source": [
    "##### Speed up for case14 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "1f5269ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.02 / (((60/1e6)/20)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa4febe",
   "metadata": {},
   "source": [
    "##### Speed up for neurips 2020 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "bb2bf900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.34426229508197"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.02 / (((61/1e6)/59)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c159714",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> Fully Connected model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f6de71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark2\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"CONFIG2\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53322dc",
   "metadata": {},
   "source": [
    "train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d632cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_fc.train(train_dataset=benchmark2.train_dataset,\n",
    "            val_dataset=benchmark2.val_dataset,\n",
    "            epochs=2\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3fd83",
   "metadata": {},
   "source": [
    "##### Augment the datasize to represent the realistic power network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "3c2e8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(benchmark, size=1e6):\n",
    "    data_size = benchmark._test_dataset.size\n",
    "    if size < data_size:\n",
    "        raise ValueError(\"You cannot reduce the data size using this function\")\n",
    "    factor = int(size / data_size)\n",
    "    \n",
    "    for nm_, arr_ in benchmark._test_dataset.data.items():\n",
    "        if nm_ == \"line_status\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=int)\n",
    "        elif nm_ == \"topo_vect\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=bool)\n",
    "        else:\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=np.float32)\n",
    "        \n",
    "    benchmark._test_dataset.size = int(size)\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ef0624ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = augment_data(benchmark2, size=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "52888a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark2._test_dataset.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6afd2d",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 5\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=nb_samples,\n",
    "                                                  dataset=\"test\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d6d265",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "a62f6a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.0061 ms/pf\n",
      "Inference time from Machine Learning category and using CPU: 0.0011 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "7f8b4dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 6.11 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using CPU: 1.06 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark2._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark2._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ae5a3",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "da2726ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 33.08\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 190.43\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498e991",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> LeapNet model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import LeapNet\n",
    "from lips.dataset.scaler import PowerGridScaler\n",
    "\n",
    "leap_net = LeapNet(name=\"tf_leapnet\",\n",
    "                   bench_config_path=BENCH_CONFIG_PATH,\n",
    "                   bench_config_name=\"Benchmark1\",\n",
    "                   sim_config_path=SIM_CONFIG_PATH / \"tf_leapnet.ini\",\n",
    "                   sim_config_name=\"DEFAULT\",\n",
    "                   scaler=PowerGridScaler,\n",
    "                   log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc467d5",
   "metadata": {},
   "source": [
    "Load the model for the convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark2)\n",
    "leap_net.restore(path=LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1d48e",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65051000",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    leapnet_metrics = benchmark2.evaluate_simulator(augmented_simulator=leap_net,\n",
    "                                                    eval_batch_size=128,\n",
    "                                                    dataset=\"all\",\n",
    "                                                    shuffle=False,\n",
    "                                                    save_path=None,\n",
    "                                                    save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(leapnet_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(leapnet_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3967b50",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0172b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3026aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ba4e9",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b55976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c3cfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c240768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf9cc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6447b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1fa8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef841132",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\">Environment : \"l2rpn_neurips_2020_track1_small\"</h1> <a id=\"env_nips\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "56fec130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent # it is supposed that the notebook had run from getting_started folder\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_neurips_2020_track1_small\"\n",
    "#BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_neurips_2020_track1_small.ini\"\n",
    "# DO NOT CONSIDER the TAU_VECTOR\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_neurips_2020_track1_small_time.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "TRAINED_MODEL_PATH = LIPS_PATH / \"trained_models\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233259c",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Benchmark1 </h2> <a id=\"nips_benchmark1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "9ee57f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07eaab",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"nips_solver_bench1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd66d6",
   "metadata": {},
   "source": [
    "Physics solver takes 0.02 miliseconds to solve a powerflow. However the physics solver time for the benchmark1 is computed as follows:\n",
    "$$\\underbrace{\\# samples}_\\textrm{# situations} \\times \\underbrace{(4! + 1)}_\\textrm{# topologies} \\times \\frac{\\textrm{security analysis time}}{58}$$, where $58$ is number of the lines for this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b25a6ea",
   "metadata": {},
   "source": [
    "#### Consider the preprocssing step for physical solver and security analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6bc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 3\n",
    "data_size = 1000\n",
    "\n",
    "time_physics_solver = list()\n",
    "time_preproc = list()\n",
    "for i in range(NB_RUN):\n",
    "    benchmark1_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "    \n",
    "    benchmark1_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(data_size),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    simulator = benchmark1_tmp.test_simulator\n",
    "    total_time = simulator._timer_preproc + simulator._timer_solver + simulator._timer_postproc\n",
    "    time_preproc.append(simulator._timer_preproc)\n",
    "    #total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "96f8ab54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing time required for generating 1000000 samples: 58.11s\n"
     ]
    }
   ],
   "source": [
    "nb_samples = int(1e6)\n",
    "time_preprocess = (np.mean(time_preproc) / 1000) * 1e6\n",
    "print(f\"preprocessing time required for generating {nb_samples} samples: {time_preprocess:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b0ee3",
   "metadata": {},
   "source": [
    "#### Secrity analysis step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "c3b781ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/SYSTEMX/milad/venv/lips_milad/lib/python3.8/site-packages/lightsim2grid/gridmodel/_aux_add_trafo.py:65: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_degree\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_degree\\\"], they have been replaced by 0\")\n",
      "/home/ubuntu/SYSTEMX/milad/venv/lips_milad/lib/python3.8/site-packages/lightsim2grid/gridmodel/_aux_add_slack.py:113: UserWarning: We found either some slack coefficient to be < 0. or they were all 0.We set them all to 1.0 to avoid such issues\n",
      "  warnings.warn(\"We found either some slack coefficient to be < 0. or they were all 0.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For environment: l2rpn_neurips_2020_track1_small (58 n-1 simulated)\n",
      "Total time spent in \"computer\" to solve everything: 1.9ms (30569 pf / s), 0.03 ms / pf)\n",
      "\t - time to compute the coefficients to simulate line disconnection: 0.01ms\n",
      "\t - time to pre process Ybus: 0.13ms\n",
      "\t - time to perform powerflows: 1.72ms (33637 pf / s, 0.03 ms / pf)\n",
      "In addition, it took 0.09 ms to retrieve the current from the complex voltages (in total 29201.9 pf /s, 0.03 ms / pf)\n"
     ]
    }
   ],
   "source": [
    "import grid2op\n",
    "from grid2op.Parameters import Parameters\n",
    "from lightsim2grid import LightSimBackend, SecurityAnalysis\n",
    "\n",
    "env_name = \"l2rpn_neurips_2020_track1_small\"\n",
    "\n",
    "test = False\n",
    "# Create the grid2op environment\n",
    "param = Parameters()\n",
    "param.NO_OVERFLOW_DISCONNECTION = True\n",
    "env = grid2op.make(env_name,\n",
    "                   backend=LightSimBackend(),\n",
    "                   # ignore the protection, that are NOT simulated\n",
    "                   # by the TimeSerie module !\n",
    "                   param=param,\n",
    "                   test=test)\n",
    "\n",
    "# Run the environment on a scenario using the TimeSerie module\n",
    "NB_RUN = 10\n",
    "total_times = list()\n",
    "sa_time = list()\n",
    "for i in range(NB_RUN):\n",
    "    env.fast_forward_chronics(2*24*(60/5))\n",
    "    beg_ = time.perf_counter()\n",
    "    security_analysis = SecurityAnalysis(env)\n",
    "    security_analysis.add_all_n1_contingencies()\n",
    "    p_or, a_or, voltages = security_analysis.get_flows()\n",
    "    sa_time.append(time.perf_counter() - beg_)\n",
    "    total_times.append(security_analysis.computer.total_time())\n",
    "    \n",
    "# the 3 lines above are the only lines you need to do to perform a security analysis !\n",
    "\n",
    "computer = security_analysis.computer\n",
    "print(f\"For environment: {env_name} ({computer.nb_solved()} n-1 simulated)\")\n",
    "print(f\"Total time spent in \\\"computer\\\" to solve everything: {1e3*computer.total_time():.1f}ms \"\n",
    "      f\"({computer.nb_solved() / computer.total_time():.0f} pf / s), \"\n",
    "      f\"{1000.*computer.total_time() / computer.nb_solved():.2f} ms / pf)\")\n",
    "print(f\"\\t - time to compute the coefficients to simulate line disconnection: {1e3*computer.preprocessing_time():.2f}ms\")\n",
    "print(f\"\\t - time to pre process Ybus: {1e3*computer.modif_Ybus_time():.2f}ms\")\n",
    "print(f\"\\t - time to perform powerflows: {1e3*computer.solver_time():.2f}ms \"\n",
    "      f\"({computer.nb_solved() / computer.solver_time():.0f} pf / s, \"\n",
    "      f\"{1000.*computer.solver_time() / computer.nb_solved():.2f} ms / pf)\")\n",
    "print(f\"In addition, it took {1e3*computer.amps_computation_time():.2f} ms to retrieve the current \"\n",
    "      f\"from the complex voltages (in total \"\n",
    "      f\"{computer.nb_solved() / ( computer.total_time() + computer.amps_computation_time()):.1f} \"\n",
    "      \"pf /s, \"\n",
    "      f\"{1000.*( computer.total_time() + computer.amps_computation_time()) / computer.nb_solved():.2f} ms / pf)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "056e3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.82 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "nb_samples = int(1e6)\n",
    "# with preprocessing step\n",
    "# physics_solver_time = ((1e3*computer.total_time() / computer.nb_solved()) * nb_samples)/1e3 + time_preprocess\n",
    "# without preprocessing step\n",
    "physics_solver_time = ((1e3*computer.total_time() / computer.nb_solved()) * nb_samples)/1e3\n",
    "print(f\"{physics_solver_time:.2f} s for {nb_samples} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "bdf67f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019630374596454205"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sa_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cd768",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> Fully connected model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "c7bf7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"CONFIG2\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_fc.train(train_dataset=benchmark1.train_dataset,\n",
    "            val_dataset=benchmark1.val_dataset,\n",
    "            epochs=2\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd5456",
   "metadata": {},
   "source": [
    "##### Augment the datasize to represent the realistic power network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "216c2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(benchmark, size=1e6):\n",
    "    data_size = benchmark._test_dataset.size\n",
    "    if size < data_size:\n",
    "        raise ValueError(\"You cannot reduce the data size using this function\")\n",
    "    factor = int(size / data_size)\n",
    "    \n",
    "    for nm_, arr_ in benchmark._test_dataset.data.items():\n",
    "        if nm_ == \"line_status\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=int)\n",
    "        elif nm_ == \"topo_vect\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=bool)\n",
    "        else:\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=np.float32)\n",
    "        \n",
    "    benchmark._test_dataset.size = int(size)\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "43ef39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = augment_data(benchmark1, size=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "26e4dd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark1._test_dataset.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e465fc",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 5\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=nb_samples,\n",
    "                                                  dataset=\"test\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427a371",
   "metadata": {},
   "source": [
    "The inference time should be reported per powerflow. So it should be devided by $10000$ which represents the size of the data in test data dataset. For the sake of comparison which physics solver, we would report it in miliseconds. So, it should be multiplied by $1000$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea461d3f",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "f4843ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.0018 ms/pf\n",
      "Inference time from Machine Learning category and using CPU: 0.0019 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "2161e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 1.81 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using CPU: 1.92 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93237e6",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "7c063460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 50.24\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 47.36\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2716106",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Benchmark2 </h2> <a id=\"nips_benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "15bb4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c00ccb",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"nips_solver_bench2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaee5b",
   "metadata": {},
   "source": [
    "Apart of first benchmark (security analysis) where the inverse of `Y_bus` matrix could be computed once and the observatiosn could be generated in parallel, the other two benchmarks require to compute this matrix inversion for each flow computation. Hence, to be able to compute the physics solver time, we can use the following times:\n",
    "\n",
    "$$ \\textrm{_timer_preproc} + \\textrm{_timer_solver} + \\textrm{_timer_postproc}$$\n",
    "\n",
    "The details explanations for each of these steps are provided [here](https://docs.google.com/document/d/1MWj1NUj4hbPuMMzu0ty9Md_qk9mnLz88chEOi3TwJJU/edit#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b159a9",
   "metadata": {},
   "source": [
    "In the next cell we compute the flow over 1000 observations, and finally we report the time required for one powerflow to be comptued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431dde54",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 3\n",
    "data_size = 1000\n",
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "time_physics_solver = list()\n",
    "dc_time = list()\n",
    "for i in range(NB_RUN):\n",
    "    benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(data_size),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    simulator = benchmark2_tmp.test_simulator\n",
    "    total_time = simulator._timer_preproc + simulator._timer_solver + simulator._timer_postproc\n",
    "    dc_time.append(simulator._timer_preproc)\n",
    "    #total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "23fa7f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics solver computation time for benchmark 2 over 3 runs is: 90.81932193677179s for 1000 samples\n",
      "Physics solver computation time for benchmark 2 over 3 runs and for one powerflow is: 90.81932193677179 ms/pf\n"
     ]
    }
   ],
   "source": [
    "physics_solver_time_env1_bench2 = np.mean(time_physics_solver)\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs is: {}s for {} samples\".format(NB_RUN, physics_solver_time, data_size))\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs and for one powerflow is: {} ms/pf\".format(NB_RUN, (physics_solver_time/data_size)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "93f9ecbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294.07 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "nb_samples = int(1e6)\n",
    "physics_solver_time = (physics_solver_time_env1_bench2/1000)*nb_samples\n",
    "print(f\"{physics_solver_time:.2f} s for {nb_samples} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "50a05ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.00984528226157\n"
     ]
    }
   ],
   "source": [
    "DC_solver_time = (np.mean(dc_time)/1000)*nb_samples\n",
    "print(DC_solver_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1e48a2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.639344262295082"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "283/61"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf28ea",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> Fully Connected model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "d3ac652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"CONFIG2\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eab12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_fc.train(train_dataset=benchmark2.train_dataset,\n",
    "            val_dataset=benchmark2.val_dataset,\n",
    "            epochs=2\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce45ad9",
   "metadata": {},
   "source": [
    "##### Augment the datasize to represent the realistic power network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0a7172e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(benchmark, size=1e6):\n",
    "    data_size = benchmark._test_dataset.size\n",
    "    if size < data_size:\n",
    "        raise ValueError(\"You cannot reduce the data size using this function\")\n",
    "    factor = int(size / data_size)\n",
    "    \n",
    "    for nm_, arr_ in benchmark._test_dataset.data.items():\n",
    "        if nm_ == \"line_status\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=int)\n",
    "        elif nm_ == \"topo_vect\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=bool)\n",
    "        else:\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=np.float32)\n",
    "        \n",
    "    benchmark._test_dataset.size = int(size)\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "1ed1165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = augment_data(benchmark2, size=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "70c0c972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark2._test_dataset.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d3ac1e",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91137df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 5\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=nb_samples,\n",
    "                                                  dataset=\"test\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe7f9f",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "2813248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.0060 ms/pf\n",
      "Inference time from Machine Learning category and using CPU: 0.0034 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "8f433098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 6.01 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using CPU: 3.44 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15fc13b",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "9eb93818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 48.93\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 85.55\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lips_milad",
   "language": "python",
   "name": "lips_milad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
