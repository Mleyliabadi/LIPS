{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69bd90c",
   "metadata": {},
   "source": [
    "# Inference time measurement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f253a0",
   "metadata": {},
   "source": [
    "To be able to run this experimentation, [Grid2op](https://github.com/rte-france/Grid2Op) (1.7.1) and [LightSim2Grid](https://github.com/BDonnot/lightsim2grid) (0.7.0) are required. See the corresponding links for more information concerning their installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29ea519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "from lips.utils import get_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926afae9",
   "metadata": {},
   "source": [
    "# TOC\n",
    "- [Device Selection](#device)\n",
    "- [Environment: `l2rpn_case14_sandbox`](#env_case14)\n",
    "    - [Benchmark1](#benchmark1)\n",
    "        - [Physics solver time](#14_solver_bench1)\n",
    "    - [Benchmark2](#benchmark2)\n",
    "        - [Physics solver time](#14_solver_bench2)\n",
    "- [Environment: `l2rpn_neurips_2020_track1_small`](#env_nips)\n",
    "    - [Benchmark1](#nips_benchmark1)\n",
    "        - [Physics solver time](#nips_solver_bench1)\n",
    "    - [Benchmark2](#nips_benchmark2)\n",
    "        - [Physics solver time](#nips_solver_bench2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd639c0",
   "metadata": {},
   "source": [
    "## Select a device on which the model should be evaluated <a id=\"device\"></a>\n",
    "On the basis of GPU or CPU device, the results may be vary significantly. You can choose one of the following block in each kernel to using whether GPU or CPU device. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890432fc",
   "metadata": {},
   "source": [
    "### Using A GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1812cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device = \"GPU\"\n",
    "gpus = tf.config.experimental.list_physical_devices(device)\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[3], device)\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d73cc",
   "metadata": {},
   "source": [
    "### Using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383c8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = \"CPU\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd41961",
   "metadata": {},
   "source": [
    "### Show the list of used devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd048bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78175a81",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\">Environment : \"l2rpn_case14_sandbox\"</h1> <a id=\"env_case14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7486a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent # it is supposed that the notebook had run from getting_started folder\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_case14_sandbox\"\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_case14_sandbox.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "TRAINED_MODEL_PATH = LIPS_PATH / \"trained_models\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7a0b8",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Benchmark1 </h2> <a id=\"benchmark1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1411fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4385b938",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"14_solver_bench1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0abc3e",
   "metadata": {},
   "source": [
    "Physics solver takes 0.02 miliseconds to solve a powerflow. However the physics solver time for the benchmark1 is computed as follows:\n",
    "$$\\underbrace{\\#Samples}_\\textrm{# situations} \\times \\underbrace{(3! + 1)}_\\textrm{# topologies} \\times \\frac{\\textrm{security analysis time}}{20}$$, where $20$ is number of the lines in this benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9d7c0",
   "metadata": {},
   "source": [
    "Do the Security Analysis. Source : https://github.com/BDonnot/lightsim2grid/blob/master/examples/security_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70e55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For environment: l2rpn_case14_sandbox (19 n-1 simulated)\n",
      "Total time spent in \"computer\" to solve everything: 0.4ms (52145 pf / s), 0.02 ms / pf)\n",
      "\t - time to compute the coefficients to simulate line disconnection: 0.01ms\n",
      "\t - time to pre process Ybus: 0.03ms\n",
      "\t - time to perform powerflows: 0.32ms (58712 pf / s, 0.02 ms / pf)\n",
      "In addition, it took 0.01 ms to retrieve the current from the complex voltages (in total 50223.9 pf /s, 0.02 ms / pf)\n"
     ]
    }
   ],
   "source": [
    "import grid2op\n",
    "from grid2op.Parameters import Parameters\n",
    "from lightsim2grid import LightSimBackend, SecurityAnalysis\n",
    "\n",
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "\n",
    "test = False\n",
    "# Create the grid2op environment\n",
    "param = Parameters()\n",
    "param.NO_OVERFLOW_DISCONNECTION = True\n",
    "env = grid2op.make(env_name,\n",
    "                   backend=LightSimBackend(),\n",
    "                   # ignore the protection, that are NOT simulated\n",
    "                   # by the TimeSerie module !\n",
    "                   param=param,\n",
    "                   test=test)\n",
    "\n",
    "# Run the environment on a scenario using the TimeSerie module\n",
    "security_analysis = SecurityAnalysis(env)\n",
    "security_analysis.add_all_n1_contingencies()\n",
    "p_or, a_or, voltages = security_analysis.get_flows()\n",
    "# the 3 lines above are the only lines you need to do to perform a security analysis !\n",
    "\n",
    "computer = security_analysis.computer\n",
    "print(f\"For environment: {env_name} ({computer.nb_solved()} n-1 simulated)\")\n",
    "print(f\"Total time spent in \\\"computer\\\" to solve everything: {1e3*computer.total_time():.1f}ms \"\n",
    "      f\"({computer.nb_solved() / computer.total_time():.0f} pf / s), \"\n",
    "      f\"{1000.*computer.total_time() / computer.nb_solved():.2f} ms / pf)\")\n",
    "print(f\"\\t - time to compute the coefficients to simulate line disconnection: {1e3*computer.preprocessing_time():.2f}ms\")\n",
    "print(f\"\\t - time to pre process Ybus: {1e3*computer.modif_Ybus_time():.2f}ms\")\n",
    "print(f\"\\t - time to perform powerflows: {1e3*computer.solver_time():.2f}ms \"\n",
    "      f\"({computer.nb_solved() / computer.solver_time():.0f} pf / s, \"\n",
    "      f\"{1000.*computer.solver_time() / computer.nb_solved():.2f} ms / pf)\")\n",
    "print(f\"In addition, it took {1e3*computer.amps_computation_time():.2f} ms to retrieve the current \"\n",
    "      f\"from the complex voltages (in total \"\n",
    "      f\"{computer.nb_solved() / ( computer.total_time() + computer.amps_computation_time()):.1f} \"\n",
    "      \"pf /s, \"\n",
    "      f\"{1000.*( computer.total_time() + computer.amps_computation_time()) / computer.nb_solved():.2f} ms / pf)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840af82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.18 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "nb_samples = int(1e6)\n",
    "physics_solver_time = ((1e3*computer.total_time() / computer.nb_solved()) * nb_samples)/1e3\n",
    "print(f\"{physics_solver_time:.2f} s for {nb_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1c1df",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> Fully connected model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8796421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f207513",
   "metadata": {},
   "source": [
    "##### Load it from a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121e14c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 13:44:17.566689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark1)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d03c47",
   "metadata": {},
   "source": [
    "##### Augment the datasize to represent the realistic power network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf2e11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(benchmark, size=1e6):\n",
    "    data_size = benchmark._test_dataset.size\n",
    "    if size < data_size:\n",
    "        raise ValueError(\"You cannot reduce the data size using this function\")\n",
    "    factor = int(size / data_size)\n",
    "    \n",
    "    for nm_, arr_ in benchmark._test_dataset.data.items():\n",
    "        if nm_ == \"line_status\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=int)\n",
    "        elif nm_ == \"topo_vect\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=bool)\n",
    "        else:\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=np.float32)\n",
    "        \n",
    "    benchmark._test_dataset.size = int(size)\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "360ba525",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = augment_data(benchmark1, size=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9200f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark1._test_dataset.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538a212",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a7711",
   "metadata": {},
   "source": [
    "###### Run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb55910",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                              eval_batch_size=128,\n",
    "                                              dataset=\"test\",\n",
    "                                              shuffle=False,\n",
    "                                              save_path=None,\n",
    "                                              save_predictions=False\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f4bca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5277208059560508\n",
      "17.477608849992976\n"
     ]
    }
   ],
   "source": [
    "print(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "print(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861d501",
   "metadata": {},
   "source": [
    "###### Run multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c657bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 5\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"test\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e66dc",
   "metadata": {},
   "source": [
    "The inference time should be reported per powerflow. So it should be devided by $10000$ which represents the size of the data in test data dataset. For the sake of comparison which physics solver, we would report it in miliseconds. So, it should be multiplied by $1000$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb693493",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10f595c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.0176 ms/pf\n",
      "Inference time from Machine Learning category and using CPU: 0.0015 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66147165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 17.61 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using CPU: 1.47 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da21474",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7c7ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 1.09\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 13.06\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e20d9",
   "metadata": {},
   "source": [
    "###### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57b44b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 1.42 ms/pf\n",
      "Inference time from Machine Learning category and using GPU: 0.12 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4da417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 14.25 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using GPU: 1.25 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7cc004",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28b65daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and GPU is: 1.25\n",
      "Speed up factor from ML point of view using FullyConnected model and GPU is: 14.23\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8b2c2",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> LeapNet model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35041d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import LeapNet\n",
    "from lips.dataset.scaler import PowerGridScaler\n",
    "\n",
    "leap_net = LeapNet(name=\"tf_leapnet\",\n",
    "                   bench_config_path=BENCH_CONFIG_PATH,\n",
    "                   bench_config_name=\"Benchmark1\",\n",
    "                   sim_config_path=SIM_CONFIG_PATH / \"tf_leapnet.ini\",\n",
    "                   sim_config_name=\"DEFAULT\",\n",
    "                   scaler=PowerGridScaler,\n",
    "                   log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29319fe5",
   "metadata": {},
   "source": [
    "Load the model for the convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "559eea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark1)\n",
    "leap_net.restore(path=LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab3779",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    leapnet_metrics = benchmark1.evaluate_simulator(augmented_simulator=leap_net,\n",
    "                                                    eval_batch_size=128,\n",
    "                                                    dataset=\"test\",\n",
    "                                                    shuffle=False,\n",
    "                                                    save_path=None,\n",
    "                                                    save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(leapnet_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(leapnet_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2beef5",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03947d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1429c5",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9717755",
   "metadata": {},
   "source": [
    "###### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a843245",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ddc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb76d5",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2d803",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Benchmark2</h2> <a id=\"benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb726bd4",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"14_solver_bench2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b8af8",
   "metadata": {},
   "source": [
    "Apart of first benchmark (security analysis) where the inverse of `Y_bus` matrix could be computed once and the observatiosn could be generated in parallel, the other two benchmarks require to compute this matrix inversion for each flow computation. Hence, to be able to compute the physics solver time, we can use the following times:\n",
    "\n",
    "$$ \\textrm{_timer_preproc} + \\textrm{_timer_solver} + \\textrm{_timer_postproc}$$\n",
    "\n",
    "The details explanations for each of these steps are provided [here](https://docs.google.com/document/d/1MWj1NUj4hbPuMMzu0ty9Md_qk9mnLz88chEOi3TwJJU/edit#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13995216",
   "metadata": {},
   "source": [
    "In the next cell we compute the flow over 1000 observations, and finally we report the time required for one powerflow to be comptued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "time_physics_solver = list()\n",
    "for i in range(NB_RUN):\n",
    "    benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(10000),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    simulator = benchmark2_tmp.test_simulator\n",
    "    total_time = simulator._timer_preproc + simulator._timer_solver + simulator._timer_postproc\n",
    "    #total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa35d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = np.mean(time_physics_solver)\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs is: {} s\".format(NB_RUN, physics_solver_time))\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs and for one powerflow is: {} ms\".format(NB_RUN, (physics_solver_time/10000)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = 1.9429454155266286"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c159714",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> Fully Connected model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2039cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark2)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6afd2d",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"test\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188a8ca",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e51530",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b3a5a",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2378e",
   "metadata": {},
   "source": [
    "###### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64341b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e462b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebf31c",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd555a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498e991",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> LeapNet model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import LeapNet\n",
    "from lips.dataset.scaler import PowerGridScaler\n",
    "\n",
    "leap_net = LeapNet(name=\"tf_leapnet\",\n",
    "                   bench_config_path=BENCH_CONFIG_PATH,\n",
    "                   bench_config_name=\"Benchmark1\",\n",
    "                   sim_config_path=SIM_CONFIG_PATH / \"tf_leapnet.ini\",\n",
    "                   sim_config_name=\"DEFAULT\",\n",
    "                   scaler=PowerGridScaler,\n",
    "                   log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc467d5",
   "metadata": {},
   "source": [
    "Load the model for the convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark2)\n",
    "leap_net.restore(path=LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1d48e",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65051000",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    leapnet_metrics = benchmark2.evaluate_simulator(augmented_simulator=leap_net,\n",
    "                                                    eval_batch_size=128,\n",
    "                                                    dataset=\"all\",\n",
    "                                                    shuffle=False,\n",
    "                                                    save_path=None,\n",
    "                                                    save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(leapnet_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(leapnet_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3967b50",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0172b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3026aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ba4e9",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca121df",
   "metadata": {},
   "source": [
    "###### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2530fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e578044",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f109d5",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b01b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa683aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef841132",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\">Environment : \"l2rpn_neurips_2020_track1_small\"</h1> <a id=\"env_nips\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56fec130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent # it is supposed that the notebook had run from getting_started folder\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_neurips_2020_track1_small\"\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_neurips_2020_track1_small.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "TRAINED_MODEL_PATH = LIPS_PATH / \"trained_models\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233259c",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Benchmark1 </h2> <a id=\"nips_benchmark1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ee57f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07eaab",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"nips_solver_bench1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd66d6",
   "metadata": {},
   "source": [
    "Physics solver takes 0.02 miliseconds to solve a powerflow. However the physics solver time for the benchmark1 is computed as follows:\n",
    "$$\\underbrace{\\# samples}_\\textrm{# situations} \\times \\underbrace{(4! + 1)}_\\textrm{# topologies} \\times \\frac{\\textrm{security analysis time}}{58}$$, where $58$ is number of the lines for this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3b781ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/SYSTEMX/milad/venv/lips_milad/lib/python3.8/site-packages/lightsim2grid/gridmodel/_aux_add_trafo.py:65: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_degree\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_degree\\\"], they have been replaced by 0\")\n",
      "/home/ubuntu/SYSTEMX/milad/venv/lips_milad/lib/python3.8/site-packages/lightsim2grid/gridmodel/_aux_add_slack.py:113: UserWarning: We found either some slack coefficient to be < 0. or they were all 0.We set them all to 1.0 to avoid such issues\n",
      "  warnings.warn(\"We found either some slack coefficient to be < 0. or they were all 0.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For environment: l2rpn_neurips_2020_track1_small (58 n-1 simulated)\n",
      "Total time spent in \"computer\" to solve everything: 1.9ms (30576 pf / s), 0.03 ms / pf)\n",
      "\t - time to compute the coefficients to simulate line disconnection: 0.02ms\n",
      "\t - time to pre process Ybus: 0.15ms\n",
      "\t - time to perform powerflows: 1.70ms (34105 pf / s, 0.03 ms / pf)\n",
      "In addition, it took 0.08 ms to retrieve the current from the complex voltages (in total 29275.9 pf /s, 0.03 ms / pf)\n"
     ]
    }
   ],
   "source": [
    "import grid2op\n",
    "from grid2op.Parameters import Parameters\n",
    "from lightsim2grid import LightSimBackend, SecurityAnalysis\n",
    "\n",
    "env_name = \"l2rpn_neurips_2020_track1_small\"\n",
    "\n",
    "test = False\n",
    "# Create the grid2op environment\n",
    "param = Parameters()\n",
    "param.NO_OVERFLOW_DISCONNECTION = True\n",
    "env = grid2op.make(env_name,\n",
    "                   backend=LightSimBackend(),\n",
    "                   # ignore the protection, that are NOT simulated\n",
    "                   # by the TimeSerie module !\n",
    "                   param=param,\n",
    "                   test=test)\n",
    "\n",
    "# Run the environment on a scenario using the TimeSerie module\n",
    "security_analysis = SecurityAnalysis(env)\n",
    "security_analysis.add_all_n1_contingencies()\n",
    "p_or, a_or, voltages = security_analysis.get_flows()\n",
    "# the 3 lines above are the only lines you need to do to perform a security analysis !\n",
    "\n",
    "computer = security_analysis.computer\n",
    "print(f\"For environment: {env_name} ({computer.nb_solved()} n-1 simulated)\")\n",
    "print(f\"Total time spent in \\\"computer\\\" to solve everything: {1e3*computer.total_time():.1f}ms \"\n",
    "      f\"({computer.nb_solved() / computer.total_time():.0f} pf / s), \"\n",
    "      f\"{1000.*computer.total_time() / computer.nb_solved():.2f} ms / pf)\")\n",
    "print(f\"\\t - time to compute the coefficients to simulate line disconnection: {1e3*computer.preprocessing_time():.2f}ms\")\n",
    "print(f\"\\t - time to pre process Ybus: {1e3*computer.modif_Ybus_time():.2f}ms\")\n",
    "print(f\"\\t - time to perform powerflows: {1e3*computer.solver_time():.2f}ms \"\n",
    "      f\"({computer.nb_solved() / computer.solver_time():.0f} pf / s, \"\n",
    "      f\"{1000.*computer.solver_time() / computer.nb_solved():.2f} ms / pf)\")\n",
    "print(f\"In addition, it took {1e3*computer.amps_computation_time():.2f} ms to retrieve the current \"\n",
    "      f\"from the complex voltages (in total \"\n",
    "      f\"{computer.nb_solved() / ( computer.total_time() + computer.amps_computation_time()):.1f} \"\n",
    "      \"pf /s, \"\n",
    "      f\"{1000.*( computer.total_time() + computer.amps_computation_time()) / computer.nb_solved():.2f} ms / pf)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "056e3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.71 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "nb_samples = int(1e6)\n",
    "physics_solver_time = ((1e3*computer.total_time() / computer.nb_solved()) * nb_samples)/1e3\n",
    "print(f\"{physics_solver_time:.2f} s for {nb_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cd768",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> Fully connected model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7bf7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da75d97",
   "metadata": {},
   "source": [
    "##### Load it from a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "306aa112",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(TRAINED_MODEL_PATH, benchmark1)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd5456",
   "metadata": {},
   "source": [
    "##### Augment the datasize to represent the realistic power network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "216c2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(benchmark, size=1e6):\n",
    "    data_size = benchmark._test_dataset.size\n",
    "    if size < data_size:\n",
    "        raise ValueError(\"You cannot reduce the data size using this function\")\n",
    "    factor = int(size / data_size)\n",
    "    \n",
    "    for nm_, arr_ in benchmark._test_dataset.data.items():\n",
    "        if nm_ == \"line_status\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=int)\n",
    "        elif nm_ == \"topo_vect\":\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=bool)\n",
    "        else:\n",
    "            benchmark._test_dataset.data[nm_] = np.asarray(np.tile(arr_, (factor, 1)), dtype=np.float32)\n",
    "        \n",
    "    benchmark._test_dataset.size = int(size)\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43ef39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = augment_data(benchmark1, size=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26e4dd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark1._test_dataset.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e465fc",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 5\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"test\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427a371",
   "metadata": {},
   "source": [
    "The inference time should be reported per powerflow. So it should be devided by $10000$ which represents the size of the data in test data dataset. For the sake of comparison which physics solver, we would report it in miliseconds. So, it should be multiplied by $1000$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea461d3f",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4843ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 0.0094 ms/pf\n",
      "Inference time from Machine Learning category and using CPU: 0.0030 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2161e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using CPU: 9.40 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using CPU: 3.03 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93237e6",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c063460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and CPU is: 3.48\n",
      "Speed up factor from ML point of view using FullyConnected model and CPU is: 10.79\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824326f0",
   "metadata": {},
   "source": [
    "###### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b95d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 0.0075 ms/pf\n",
      "Inference time from Machine Learning category and using GPU: 0.0034 ms/pf\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "384cd26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time from Industrial Readiness category and using GPU: 7.52 s for 1000000 samples\n",
      "Inference time from Machine Learning category and using GPU: 3.39 s for 1000000 samples\n"
     ]
    }
   ],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ab3ed",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1ae5b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up factor from IndRed point of view using FullyConnected model and GPU is: 4.36\n",
      "Speed up factor from ML point of view using FullyConnected model and GPU is: 9.65\n"
     ]
    }
   ],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2716106",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\"> Benchmark2 </h2> <a id=\"nips_benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c00ccb",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"nips_solver_bench2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaee5b",
   "metadata": {},
   "source": [
    "Apart of first benchmark (security analysis) where the inverse of `Y_bus` matrix could be computed once and the observatiosn could be generated in parallel, the other two benchmarks require to compute this matrix inversion for each flow computation. Hence, to be able to compute the physics solver time, we can use the following times:\n",
    "\n",
    "$$ \\textrm{_timer_preproc} + \\textrm{_timer_solver} + \\textrm{_timer_postproc}$$\n",
    "\n",
    "The details explanations for each of these steps are provided [here](https://docs.google.com/document/d/1MWj1NUj4hbPuMMzu0ty9Md_qk9mnLz88chEOi3TwJJU/edit#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b159a9",
   "metadata": {},
   "source": [
    "In the next cell we compute the flow over 1000 observations, and finally we report the time required for one powerflow to be comptued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a2ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "time_physics_solver = list()\n",
    "for i in range(NB_RUN):\n",
    "    benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(10000),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    simulator = benchmark2_tmp.test_simulator\n",
    "    total_time = simulator._timer_preproc + simulator._timer_solver + simulator._timer_postproc\n",
    "    #total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67685d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = np.mean(time_physics_solver)\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs is: {} s\".format(NB_RUN, physics_solver_time))\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs and for one powerflow is: {} ms\".format(NB_RUN, (physics_solver_time/10000)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85395d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = 2.8298422046704217"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf28ea",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\"> Fully Connected model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(TRAINED_MODEL_PATH, benchmark2)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74b0e7",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(10):\n",
    "    tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"TIME_INF\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"TIME_INF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76d0c34",
   "metadata": {},
   "source": [
    "######  CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a74cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a243f5",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929715a6",
   "metadata": {},
   "source": [
    "###### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ea2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_per_pf = (np.mean(time_ind) / nb_samples) * 1000\n",
    "inf_time_ML_per_pf = (np.mean(time_ml) / nb_samples) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.4f} ms/pf\".format(device, inf_time_IndRed_per_pf))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.4f} ms/pf\".format(device, inf_time_ML_per_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a16a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed_total = np.mean(time_ind)\n",
    "inf_time_ML_per_total = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} s for {} samples\".format(device, inf_time_IndRed_total, benchmark1._test_dataset.size))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} s for {} samples\".format(device, inf_time_ML_per_total, benchmark1._test_dataset.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5fc31",
   "metadata": {},
   "source": [
    "Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed_total)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML_per_total)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lips_milad",
   "language": "python",
   "name": "lips_milad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
