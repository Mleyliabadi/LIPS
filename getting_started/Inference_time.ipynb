{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69bd90c",
   "metadata": {},
   "source": [
    "# Inference time measurement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f253a0",
   "metadata": {},
   "source": [
    "To be able to run this experimentation, [Grid2op](https://github.com/rte-france/Grid2Op) (1.7.1) and [LightSim2Grid](https://github.com/BDonnot/lightsim2grid) (0.7.0) are required. See the corresponding links for more information concerning their installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ea519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "from lips.utils import get_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926afae9",
   "metadata": {},
   "source": [
    "# TOC\n",
    "- [Device Selection](#device)\n",
    "- [Environment: `l2rpn_case14_sandbox`](#env_case14)\n",
    "    - [Benchmark Selection](#benchmark_select)\n",
    "      - [Benchmark1](#benchmark1)\n",
    "          - [Physics solver time](#14_solver_bench1)\n",
    "      - [Benchmark2](#benchmark2)\n",
    "          - [Physics solver time](#14_solver_bench2)\n",
    "- [Environment: `l2rpn_neurips_2020_track1_small`](#env_nips)\n",
    "    - [Benchmark1](#nips_benchmark1)\n",
    "        - [Physics solver time](#nips_solver_bench1)\n",
    "    - [Benchmark2](#nips_benchmark2)\n",
    "        - [Physics solver time](#nips_solver_bench2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd639c0",
   "metadata": {},
   "source": [
    "## Select a device on which the model should be evaluated <a id=\"device\"></a>\n",
    "On the basis of GPU or CPU device, the results may be vary significantly. You can choose one of the following block in each kernel to using whether GPU or CPU device. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890432fc",
   "metadata": {},
   "source": [
    "### Using A GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1812cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device = \"GPU\"\n",
    "gpus = tf.config.experimental.list_physical_devices(device)\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[3], device)\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d73cc",
   "metadata": {},
   "source": [
    "### Using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = \"CPU\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd41961",
   "metadata": {},
   "source": [
    "### Show the list of used devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd048bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78175a81",
   "metadata": {},
   "source": [
    "# Environment : \"l2rpn_case14_sandbox\" <a id=\"env_case14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7486a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent # it is supposed that the notebook had run from getting_started folder\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_case14_sandbox\"\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_case14_sandbox.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "TRAINED_MODEL_PATH = LIPS_PATH / \"trained_models\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7754c87",
   "metadata": {},
   "source": [
    "## Select a benchmark <a id=\"benchmark_select\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7a0b8",
   "metadata": {},
   "source": [
    "### Benchmark1 <a id=\"benchmark1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4385b938",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"14_solver_bench1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0abc3e",
   "metadata": {},
   "source": [
    "Physics solver takes 0.02 miliseconds to solve a powerflow. However the physics solver time for the benchmark1 is computed as follows:\n",
    "$$\\underbrace{3}_\\textrm{# situations} \\times \\underbrace{6}_\\textrm{# topologies} \\times \\frac{\\textrm{security analysis time}}{20}$$, where $20$ is number of the lines in this benchmark. In our case the *security analysis* takes 0.02 ms to be solved. So the solver time is $3 \\times 6 \\times \\frac{0.02}{20} = 0.018 ms$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = 0.018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc274826",
   "metadata": {},
   "source": [
    "### Select a model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1c1df",
   "metadata": {},
   "source": [
    "#### Fully connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8796421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f207513",
   "metadata": {},
   "source": [
    "##### Load it from a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e14c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark1)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538a212",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c657bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e66dc",
   "metadata": {},
   "source": [
    "The inference time should be reported per powerflow. So it should be devided by $10000$ which represents the size of the data in test data dataset. For the sake of comparison which physics solver, we would report it in miliseconds. So, it should be multiplied by $1000$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f595c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817294c7",
   "metadata": {},
   "source": [
    "##### Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66689d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8b2c2",
   "metadata": {},
   "source": [
    "#### LeapNet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35041d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import LeapNet\n",
    "from lips.dataset.scaler import PowerGridScaler\n",
    "\n",
    "leap_net = LeapNet(name=\"tf_leapnet\",\n",
    "                   bench_config_path=BENCH_CONFIG_PATH,\n",
    "                   bench_config_name=\"Benchmark1\",\n",
    "                   sim_config_path=SIM_CONFIG_PATH / \"tf_leapnet.ini\",\n",
    "                   sim_config_name=\"DEFAULT\",\n",
    "                   scaler=PowerGridScaler,\n",
    "                   log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29319fe5",
   "metadata": {},
   "source": [
    "Load the model for the convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559eea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark1)\n",
    "leap_net.restore(path=LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab3779",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    leapnet_metrics = benchmark1.evaluate_simulator(augmented_simulator=leap_net,\n",
    "                                                    eval_batch_size=128,\n",
    "                                                    dataset=\"all\",\n",
    "                                                    shuffle=False,\n",
    "                                                    save_path=None,\n",
    "                                                    save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(leapnet_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(leapnet_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ec79a",
   "metadata": {},
   "source": [
    "##### Computing the speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using LeapNet model and {} is: {:.2f}\".format(device, (0.36 / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using LeapNet model and {} is: {:.2f}\".format(device, (0.36 / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using LeapNet model and {} is: {:.2f}\".format(device, (0.36 / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using LeapNet model and {} is: {:.2f}\".format(device, (0.36 / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2d803",
   "metadata": {},
   "source": [
    "## Benchmark2 <a id=\"benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb726bd4",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"14_solver_bench2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b8af8",
   "metadata": {},
   "source": [
    "Apart of first benchmark (security analysis) where the inverse of `Y_bus` matrix could be computed once and the observatiosn could be generated in parallel, the other two benchmarks require to compute this matrix inversion for each flow computation. Hence, to be able to compute the physics solver time, we can use the following times:\n",
    "\n",
    "$$ \\textrm{_timer_preproc} + \\textrm{_timer_solver} + \\textrm{_timer_postproc}$$\n",
    "\n",
    "The details explanations for each of these steps are provided [here](https://docs.google.com/document/d/1MWj1NUj4hbPuMMzu0ty9Md_qk9mnLz88chEOi3TwJJU/edit#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13995216",
   "metadata": {},
   "source": [
    "In the next cell we compute the flow over 1000 observations, and finally we report the time required for one powerflow to be comptued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "time_physics_solver = list()\n",
    "for i in range(NB_RUN):\n",
    "    benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(10000),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    simulator = benchmark2_tmp.test_simulator\n",
    "    total_time = simulator._timer_preproc + simulator._timer_solver + simulator._timer_postproc\n",
    "    #total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa35d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = np.mean(time_physics_solver)\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs is: {} s\".format(NB_RUN, physics_solver_time))\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs and for one powerflow is: {} ms\".format(NB_RUN, (physics_solver_time/10000)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = 1.9429454155266286"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82cbbff",
   "metadata": {},
   "source": [
    "### Select a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c159714",
   "metadata": {},
   "source": [
    "#### Fully Connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2039cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark2)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6afd2d",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb843f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1d9bf",
   "metadata": {},
   "source": [
    "##### Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8112cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaad00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498e991",
   "metadata": {},
   "source": [
    "#### LeapNet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import LeapNet\n",
    "from lips.dataset.scaler import PowerGridScaler\n",
    "\n",
    "leap_net = LeapNet(name=\"tf_leapnet\",\n",
    "                   bench_config_path=BENCH_CONFIG_PATH,\n",
    "                   bench_config_name=\"Benchmark1\",\n",
    "                   sim_config_path=SIM_CONFIG_PATH / \"tf_leapnet.ini\",\n",
    "                   sim_config_name=\"DEFAULT\",\n",
    "                   scaler=PowerGridScaler,\n",
    "                   log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc467d5",
   "metadata": {},
   "source": [
    "Load the model for the convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(BASELINES_PATH, benchmark2)\n",
    "leap_net.restore(path=LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1d48e",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65051000",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    leapnet_metrics = benchmark2.evaluate_simulator(augmented_simulator=leap_net,\n",
    "                                                    eval_batch_size=128,\n",
    "                                                    dataset=\"all\",\n",
    "                                                    shuffle=False,\n",
    "                                                    save_path=None,\n",
    "                                                    save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(leapnet_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(leapnet_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04752954",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7dcca6",
   "metadata": {},
   "source": [
    "##### Computing speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using LeapNet model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using LeapNet model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using LeapNet model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using LeapNet model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d2266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b8094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa683aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef841132",
   "metadata": {},
   "source": [
    "# Environment : \"l2rpn_neurips_2020_track1_small\" <a id=\"env_nips\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fec130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = pathlib.Path().resolve().parent # it is supposed that the notebook had run from getting_started folder\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_neurips_2020_track1_small\"\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_neurips_2020_track1_small.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "BASELINES_PATH = LIPS_PATH / \"trained_baselines\" / \"powergrid\"\n",
    "TRAINED_MODEL_PATH = LIPS_PATH / \"trained_models\" / \"powergrid\"\n",
    "EVALUATION_PATH = LIPS_PATH / \"evaluation_results\" / \"PowerGrid\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233259c",
   "metadata": {},
   "source": [
    "## Benchmark1 <a id=\"nips_benchmark1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee57f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark1 = PowerGridBenchmark(benchmark_name=\"Benchmark1\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07eaab",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"nips_solver_bench1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd66d6",
   "metadata": {},
   "source": [
    "Physics solver takes 0.02 miliseconds to solve a powerflow. However the physics solver time for the benchmark1 is computed as follows:\n",
    "$$\\underbrace{3}_\\textrm{# situations} \\times \\underbrace{6}_\\textrm{# topologies} \\times \\frac{\\textrm{security analysis time}}{36}$$, where $36$ is number of the lines for this environment. In our case the *security analysis* takes 0.02 ms to be solved. So the solver time is $3 \\times 6 \\times \\frac{0.03}{36} = 0.015 ms$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f131cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = 0.015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acfa23c",
   "metadata": {},
   "source": [
    "### Select a model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cd768",
   "metadata": {},
   "source": [
    "#### Fully connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da75d97",
   "metadata": {},
   "source": [
    "##### Load it from a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306aa112",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(TRAINED_MODEL_PATH, benchmark1)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e465fc",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(NB_RUN):\n",
    "    tf_fc_metrics = benchmark1.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427a371",
   "metadata": {},
   "source": [
    "The inference time should be reported per powerflow. So it should be devided by $10000$ which represents the size of the data in test data dataset. For the sake of comparison which physics solver, we would report it in miliseconds. So, it should be multiplied by $1000$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f} ms\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f} ms\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e954aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = (np.mean(time_ind) / 10000) * 1000\n",
    "inf_time_ML = (np.mean(time_ml) / 10000) * 1000\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {:.2f}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {:.2f}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b92e2",
   "metadata": {},
   "source": [
    "##### Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46720ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2716106",
   "metadata": {},
   "source": [
    "## Benchmark2 <a id=\"nips_benchmark2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                benchmark_path=DATA_PATH,\n",
    "                                load_data_set=True,\n",
    "                                log_path=LOG_PATH,\n",
    "                                config_path=BENCH_CONFIG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c00ccb",
   "metadata": {},
   "source": [
    "### Physics solver time <a id=\"nips_solver_bench2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaee5b",
   "metadata": {},
   "source": [
    "Apart of first benchmark (security analysis) where the inverse of `Y_bus` matrix could be computed once and the observatiosn could be generated in parallel, the other two benchmarks require to compute this matrix inversion for each flow computation. Hence, to be able to compute the physics solver time, we can use the following times:\n",
    "\n",
    "$$ \\textrm{_timer_preproc} + \\textrm{_timer_solver} + \\textrm{_timer_postproc}$$\n",
    "\n",
    "The details explanations for each of these steps are provided [here](https://docs.google.com/document/d/1MWj1NUj4hbPuMMzu0ty9Md_qk9mnLz88chEOi3TwJJU/edit#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b159a9",
   "metadata": {},
   "source": [
    "In the next cell we compute the flow over 1000 observations, and finally we report the time required for one powerflow to be comptued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a2ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "benchmark2_tmp = PowerGridBenchmark(benchmark_name=\"Benchmark2\",\n",
    "                                    benchmark_path=None,\n",
    "                                    load_data_set=False,\n",
    "                                    log_path=LOG_PATH,\n",
    "                                    config_path=BENCH_CONFIG_PATH\n",
    "                                   )\n",
    "time_physics_solver = list()\n",
    "for i in range(NB_RUN):\n",
    "    benchmark2_tmp.generate(nb_sample_train=int(1),\n",
    "                            nb_sample_val=int(1),\n",
    "                            nb_sample_test=int(10000),\n",
    "                            nb_sample_test_ood_topo=int(1),\n",
    "                           )\n",
    "    simulator = benchmark2_tmp.test_simulator\n",
    "    total_time = simulator._timer_preproc + simulator._timer_solver + simulator._timer_postproc\n",
    "    #total_time = benchmark2_tmp.test_simulator._simulator.backend._timer_postproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_preproc + \\\n",
    "    #             benchmark2_tmp.test_simulator._simulator.backend._timer_solver\n",
    "    time_physics_solver.append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67685d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = np.mean(time_physics_solver)\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs is: {} s\".format(NB_RUN, physics_solver_time))\n",
    "print(\"Physics solver computation time for benchmark 2 over {} runs and for one powerflow is: {} ms\".format(NB_RUN, (physics_solver_time/10000)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85395d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_solver_time = 2.8298422046704217"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada7ab7",
   "metadata": {},
   "source": [
    "### Select a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf28ea",
   "metadata": {},
   "source": [
    "#### Fully Connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.tensorflow_models import TfFullyConnected\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "tf_fc = TfFullyConnected(name=\"tf_fc\",\n",
    "                         bench_config_path=BENCH_CONFIG_PATH,\n",
    "                         bench_config_name=\"Benchmark1\",\n",
    "                         sim_config_path=SIM_CONFIG_PATH / \"tf_fc.ini\",\n",
    "                         sim_config_name=\"DEFAULT\",\n",
    "                         scaler=StandardScaler,\n",
    "                         log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = get_path(TRAINED_MODEL_PATH, benchmark2)\n",
    "tf_fc.restore(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74b0e7",
   "metadata": {},
   "source": [
    "##### Evaluate it multiple times and return the inference times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_RUN = 10\n",
    "time_ml = list()\n",
    "time_ind = list()\n",
    "for i in range(10):\n",
    "    tf_fc_metrics = benchmark2.evaluate_simulator(augmented_simulator=tf_fc,\n",
    "                                                  eval_batch_size=128,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )\n",
    "    time_ml.append(tf_fc_metrics[\"test\"][\"ML\"][\"time_inf\"])\n",
    "    time_ind.append(tf_fc_metrics[\"test\"][\"IndRed\"][\"time_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29671026",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_IndRed = np.mean(time_ind)\n",
    "inf_time_ML = np.mean(time_ml)\n",
    "print(\"Inference time from Industrial Readiness category and using {}: {}\".format(device, inf_time_IndRed))\n",
    "print(\"Inference time from Machine Learning category and using {}: {}\".format(device, inf_time_ML))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17a2b2",
   "metadata": {},
   "source": [
    "##### Computing the speed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb21f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed up factor from IndRed point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_IndRed)))\n",
    "print(\"Speed up factor from ML point of view using FullyConnected model and {} is: {:.2f}\".format(device, (physics_solver_time / inf_time_ML)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lips",
   "language": "python",
   "name": "lips"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
